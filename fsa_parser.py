import asyncio
import aiohttp
import pandas as pd
import json
import time
import logging
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
import traceback
from dataclasses import dataclass, field
import hashlib

# ================= –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø =================
@dataclass
class Config:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞"""
    # –ü—É—Ç–∏ —Ñ–∞–π–ª–æ–≤
    output_file: str = "—Ä–µ–µ—Å—Ç—Ä_—Ñ—Å–∞.xlsx"
    log_file: str = "fsa_parser.log"
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    concurrency: int = 5  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    request_timeout: int = 45
    batch_size: int = 500  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–∞–∂–¥—ã–µ 500 –∑–∞–ø–∏—Å–µ–π
    max_retries: int = 2   # –£–º–µ–Ω—å—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
    retry_delay: int = 3
    
    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
    max_records: int = 0  # 0 = –≤—Å–µ –∑–∞–ø–∏—Å–∏
    
    # –¢–æ–∫–µ–Ω –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ (–≤–∞–∂–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –µ—Å–ª–∏ –∏—Å—Ç–µ—á–µ—Ç)
    auth_token: str = "eyJhbGciOiJFZERTQSJ9.eyJpc3MiOiJGQVUgTklBIiwic3ViIjoiYW5vbnltb3VzIiwiZXhwIjoxNzcwMjk3ODA3LCJpYXQiOjE3NzAyNjkwMDd9.--K03QrNpehr2-0opkxE_63AJSErHdE1g2BMinuQlNFTtSJg058RhXKgSDcJ-nl3Wb_xJTMCURPFo5J0z8bKAw"
    
    # URL API
    base_url: str = "https://pub.fsa.gov.ru"
    company_api: str = "/api/v1/ral/common/companies/{id}"
    declaration_api: str = "/api/v1/oa/accreditation/declaration/view/"
    
    # –ó–∞–≥–æ–ª–æ–≤–∫–∏
    headers: Dict[str, str] = field(default_factory=lambda: {
        "accept": "application/json, text/plain, */*",
        "accept-language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
        "authorization": "",
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
        "referer": "https://pub.fsa.gov.ru/ral",
        "origin": "https://pub.fsa.gov.ru",
    })
    
    def __post_init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞"""
        self.headers["authorization"] = self.auth_token

CONFIG = Config()

# ================= –õ–û–ì–ò–†–û–í–ê–ù–ò–ï =================
def setup_logging():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    logger = logging.getLogger("FSAParser")
    logger.setLevel(logging.INFO)
    
    # –§–æ—Ä–º–∞—Ç—Ç–µ—Ä
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # –§–∞–π–ª–æ–≤—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
    file_handler = logging.FileHandler(CONFIG.log_file, encoding='utf-8', mode='a')
    file_handler.setFormatter(formatter)
    file_handler.setLevel(logging.INFO)
    
    # –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    console_handler.setLevel(logging.INFO)
    
    # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    logger.handlers.clear()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    # –û—Ç–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ aiohttp
    aiohttp_logger = logging.getLogger('aiohttp')
    aiohttp_logger.setLevel(logging.WARNING)
    
    return logger

logger = setup_logging()

# ================= –£–¢–ò–õ–ò–¢–´ =================
def clean_value(value: Any) -> Any:
    """–û—á–∏—Å—Ç–∫–∞ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è"""
    if value is None:
        return ""
    elif isinstance(value, bool):
        return "–î–∞" if value else "–ù–µ—Ç"
    elif isinstance(value, (dict, list)):
        try:
            return json.dumps(value, ensure_ascii=False, indent=0)
        except:
            return str(value)
    elif isinstance(value, (int, float)):
        return str(value)
    else:
        return str(value).strip()

def safe_get(data: Dict, *keys, default: Any = "") -> Any:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Å–ª–æ–≤–∞—Ä—è"""
    current = data
    for key in keys:
        if isinstance(current, dict) and key in current:
            current = current[key]
        else:
            return default
    return current if current is not None else default

def extract_company_id(source: str) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ URL –∏–ª–∏ —Å—Ç—Ä–æ–∫–∏"""
    if not source:
        return ""
    
    if 'pub.fsa.gov.ru' in source:
        parts = source.strip('/').split('/')
        for i, part in enumerate(parts):
            if part == 'view' and i + 1 < len(parts):
                return parts[i + 1]
        return parts[-2] if len(parts) > 2 else source
    
    return str(source).strip()

def generate_md5(text: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è MD5 —Ö–µ—à–∞ –¥–ª—è —Å—Ç—Ä–æ–∫–∏"""
    return hashlib.md5(text.encode('utf-8')).hexdigest()

# ================= –û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–• =================
class DataProcessor:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–∏"""
    
    @staticmethod
    def extract_company_info(company_data: Dict) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–º–ø–∞–Ω–∏–∏"""
        result = {}
        
        # –ë–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        result['id_–∫–æ–º–ø–∞–Ω–∏–∏'] = clean_value(safe_get(company_data, 'id'))
        result['—Å—Ç–∞—Ç—É—Å'] = clean_value(safe_get(company_data, 'status'))
        result['–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ'] = clean_value(safe_get(company_data, 'fullName'))
        result['—Å–æ–∫—Ä–∞—â–µ–Ω–Ω–æ–µ_–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ'] = clean_value(safe_get(company_data, 'shortName'))
        
        # –†–µ–∫–≤–∏–∑–∏—Ç—ã
        result['–∏–Ω–Ω'] = clean_value(safe_get(company_data, 'inn'))
        result['–∫–ø–ø'] = clean_value(safe_get(company_data, 'kpp'))
        result['–æ–≥—Ä–Ω'] = clean_value(safe_get(company_data, 'ogrn'))
        result['–æ–∫–ø–æ'] = clean_value(safe_get(company_data, 'okpo'))
        
        # –¢–∏–ø –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
        result['—Ç–∏–ø_–∑–∞—è–≤–∏—Ç–µ–ª—è'] = clean_value(safe_get(company_data, 'legalForm'))
        result['–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ_–ø—Ä–∞–≤–æ–≤–∞—è_—Ñ–æ—Ä–º–∞'] = clean_value(safe_get(company_data, 'legalForm'))
        result['–≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–µ_–ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ'] = clean_value(safe_get(company_data, 'isStateOwned', False))
        result['–∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω–∞—è_–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è'] = clean_value(safe_get(company_data, 'isForeign', False))
        
        # –ö–æ–Ω—Ç–∞–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        result['—Ç–µ–ª–µ—Ñ–æ–Ω'] = clean_value(safe_get(company_data, 'phone'))
        result['email'] = clean_value(safe_get(company_data, 'email'))
        result['—Å–∞–π—Ç'] = clean_value(safe_get(company_data, 'website'))
        
        # –ê–¥—Ä–µ—Å–∞
        address_data = safe_get(company_data, 'address', default={})
        if isinstance(address_data, dict):
            result['–∞–¥—Ä–µ—Å_–º–µ—Å—Ç–∞_–Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è'] = clean_value(safe_get(address_data, 'fullAddress'))
            result['–∞–¥—Ä–µ—Å_–ø–æ—á—Ç–æ–≤—ã–π'] = clean_value(safe_get(address_data, 'postalAddress'))
        else:
            result['–∞–¥—Ä–µ—Å_–º–µ—Å—Ç–∞_–Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è'] = clean_value(address_data)
        
        # –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å
        director_data = safe_get(company_data, 'director', default={})
        if isinstance(director_data, dict):
            result['—Ñ–∏–æ_—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è'] = clean_value(safe_get(director_data, 'fullName'))
            result['–¥–æ–ª–∂–Ω–æ—Å—Ç—å_—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è'] = clean_value(safe_get(director_data, 'position'))
            result['—Ç–µ–ª–µ—Ñ–æ–Ω_—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è'] = clean_value(safe_get(director_data, 'phone'))
        
        # –ù–∞–ª–æ–≥–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        tax_data = safe_get(company_data, 'taxAuthority', default={})
        if isinstance(tax_data, dict):
            result['–Ω–∞–ª–æ–≥–æ–≤—ã–π_–æ—Ä–≥–∞–Ω'] = clean_value(safe_get(tax_data, 'name'))
        else:
            result['–Ω–∞–ª–æ–≥–æ–≤—ã–π_–æ—Ä–≥–∞–Ω'] = clean_value(tax_data)
        
        result['–¥–∞—Ç–∞_–ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∏_–Ω–∞_—É—á–µ—Ç'] = clean_value(safe_get(company_data, 'registrationDate'))
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        result['–¥–∞—Ç–∞_–ø–∞—Ä—Å–∏–Ω–≥–∞'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        result['—Ö–µ—à_–¥–∞–Ω–Ω—ã—Ö'] = generate_md5(str(company_data))
        
        return result
    
    @staticmethod
    def extract_accreditation_info(company_data: Dict, decl_data: Dict) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–∫–∫—Ä–µ–¥–∏—Ç–∞—Ü–∏–∏"""
        result = {}
        
        # –î–∞–Ω–Ω—ã–µ –∏–∑ –∫–æ–º–ø–∞–Ω–∏–∏
        accreditation = safe_get(company_data, 'accreditation', default={})
        if isinstance(accreditation, dict):
            result['—É–Ω–∏–∫–∞–ª—å–Ω—ã–π_–Ω–æ–º–µ—Ä_–∑–∞–ø–∏—Å–∏'] = clean_value(safe_get(accreditation, 'accreditationNumber'))
            result['—Å—Ç–∞—Ç—É—Å_–∞–∫–∫—Ä–µ–¥–∏—Ç–∞—Ü–∏–∏'] = clean_value(safe_get(accreditation, 'status'))
            result['–¥–∞—Ç–∞_–∞–∫–∫—Ä–µ–¥–∏—Ç–∞—Ü–∏–∏'] = clean_value(safe_get(accreditation, 'accreditationDate'))
            result['—Å—Ä–æ–∫_–¥–µ–π—Å—Ç–≤–∏—è'] = clean_value(safe_get(accreditation, 'validUntil'))
        
        # –î–∞–Ω–Ω—ã–µ –∏–∑ –¥–µ–∫–ª–∞—Ä–∞—Ü–∏–∏
        if decl_data and isinstance(decl_data, dict) and decl_data.get('_status') not in ['NOT_FOUND', 'SERVER_ERROR']:
            result['–¥–∞—Ç–∞_–≤–Ω–µ—Å–µ–Ω–∏—è_–≤_—Ä–µ–µ—Å—Ç—Ä'] = clean_value(safe_get(decl_data, 'registrationDate'))
            result['–≤–∫–ª—é—á–µ–Ω_–≤_–Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é_—á–∞—Å—Ç—å'] = clean_value(safe_get(decl_data, 'inNationalRegistry', False))
            result['–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ_—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞'] = clean_value(safe_get(decl_data, 'standard', 'name'))
            
            # –û–±–ª–∞—Å—Ç—å –∞–∫–∫—Ä–µ–¥–∏—Ç–∞—Ü–∏–∏
            scope_data = safe_get(decl_data, 'accreditationScope', default=[])
            if isinstance(scope_data, list) and scope_data:
                scope_texts = []
                for item in scope_data[:5]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 5
                    if isinstance(item, dict):
                        desc = safe_get(item, 'description') or safe_get(item, 'name')
                        if desc:
                            scope_texts.append(desc)
                result['–æ–±–ª–∞—Å—Ç—å_–∞–∫–∫—Ä–µ–¥–∏—Ç–∞—Ü–∏–∏'] = clean_value(" | ".join(scope_texts))
        
        return result
    
    @staticmethod
    def process_company(company_id: str, company_data: Dict, decl_data: Dict) -> Dict[str, Any]:
        """–ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–∏"""
        result = {
            'id_–∫–æ–º–ø–∞–Ω–∏–∏': company_id,
            '—Å—Ç–∞—Ç—É—Å_–æ–±—Ä–∞–±–æ—Ç–∫–∏': '–£–°–ü–ï–®–ù–û',
            '–æ—à–∏–±–∫–∏_–¥–µ–∫–ª–∞—Ä–∞—Ü–∏–∏': '–ù–µ—Ç'
        }
        
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–º–ø–∞–Ω–∏–∏
            company_info = DataProcessor.extract_company_info(company_data)
            result.update(company_info)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞–∫–∫—Ä–µ–¥–∏—Ç–∞—Ü–∏–∏
            accreditation_info = DataProcessor.extract_accreditation_info(company_data, decl_data)
            result.update(accreditation_info)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫ –¥–µ–∫–ª–∞—Ä–∞—Ü–∏–∏
            if decl_data and decl_data.get('_status') == 'SERVER_ERROR':
                result['–æ—à–∏–±–∫–∏_–¥–µ–∫–ª–∞—Ä–∞—Ü–∏–∏'] = '–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ (500)'
                result['—Å—Ç–∞—Ç—É—Å_–æ–±—Ä–∞–±–æ—Ç–∫–∏'] = '–ß–ê–°–¢–ò–ß–ù–û'
            elif decl_data and decl_data.get('_status') == 'NOT_FOUND':
                result['–æ—à–∏–±–∫–∏_–¥–µ–∫–ª–∞—Ä–∞—Ü–∏–∏'] = '–î–µ–∫–ª–∞—Ä–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'
                result['—Å—Ç–∞—Ç—É—Å_–æ–±—Ä–∞–±–æ—Ç–∫–∏'] = '–ß–ê–°–¢–ò–ß–ù–û'
            
        except Exception as e:
            result['—Å—Ç–∞—Ç—É—Å_–æ–±—Ä–∞–±–æ—Ç–∫–∏'] = f'–û–®–ò–ë–ö–ê: {str(e)[:100]}'
            result['–æ—à–∏–±–∫–∏_–¥–µ–∫–ª–∞—Ä–∞—Ü–∏–∏'] = '–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö'
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–º–ø–∞–Ω–∏–∏ {company_id}: {e}")
        
        return result

# ================= API –ö–õ–ò–ï–ù–¢ =================
class APIClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å API –§–°–ê"""
    
    def __init__(self):
        self.base_url = CONFIG.base_url
        self.headers = CONFIG.headers.copy()
        self.timeout = aiohttp.ClientTimeout(total=CONFIG.request_timeout)
        
    async def make_request(self, session: aiohttp.ClientSession, url: str, 
                          params: Optional[Dict] = None) -> Dict:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            async with session.get(
                url, 
                params=params, 
                timeout=self.timeout,
                ssl=False
            ) as response:
                
                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç—É—Å
                if response.status != 200:
                    logger.debug(f"–ó–∞–ø—Ä–æ—Å {url} –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {response.status}")
                
                if response.status == 200:
                    return await response.json()
                elif response.status == 404:
                    return {"_status": "NOT_FOUND"}
                elif response.status == 500:
                    # –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ - –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å
                    logger.warning(f"–°–µ—Ä–≤–µ—Ä –≤–µ—Ä–Ω—É–ª 500 –¥–ª—è {url}")
                    return {"_status": "SERVER_ERROR", "status_code": 500}
                elif response.status == 429:
                    # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤
                    logger.warning(f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ (429) –¥–ª—è {url}")
                    await asyncio.sleep(10)
                    return {"_status": "TOO_MANY_REQUESTS"}
                else:
                    return {"_status": f"HTTP_{response.status}"}
                    
        except asyncio.TimeoutError:
            logger.warning(f"–¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞: {url}")
            return {"_status": "TIMEOUT"}
        except aiohttp.ClientError as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è {url}: {e}")
            return {"_status": "CLIENT_ERROR", "error": str(e)}
        except Exception as e:
            logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è {url}: {e}")
            return {"_status": "UNKNOWN_ERROR", "error": str(e)}
    
    async def get_company(self, session: aiohttp.ClientSession, company_id: str) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–∏"""
        url = f"{self.base_url}{CONFIG.company_api.format(id=company_id)}"
        return await self.make_request(session, url)
    
    async def get_declaration(self, session: aiohttp.ClientSession, doc_id: str) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–µ–∫–ª–∞—Ä–∞—Ü–∏–∏"""
        if not doc_id:
            return {"_status": "NO_DOC_ID"}
        
        url = f"{self.base_url}{CONFIG.declaration_api}"
        params = {"docId": doc_id, "alType": 5, "validate": "false"}
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–∏ –æ—à–∏–±–∫–µ 500
        result = await self.make_request(session, url, params)
        
        # –ï—Å–ª–∏ —Å–µ—Ä–≤–µ—Ä–Ω–∞—è –æ—à–∏–±–∫–∞, –ø—Ä–æ–±—É–µ–º –±–µ–∑ alType
        if result.get('_status') == 'SERVER_ERROR':
            alt_params = {"docId": doc_id, "validate": "false"}
            alt_result = await self.make_request(session, url, alt_params)
            if alt_result.get('_status') != 'SERVER_ERROR':
                return alt_result
        
        return result

# ================= –ú–ï–ù–ï–î–ñ–ï–† –î–ê–ù–ù–´–• =================
class DataManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏ –∏ —Ñ–∞–π–ª–∞–º–∏"""
    
    def __init__(self):
        self.output_file = Path(CONFIG.output_file)
        self.all_data = []
        self.processed_ids = set()
        
    def add_data(self, data: Dict):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
        company_id = data.get('id_–∫–æ–º–ø–∞–Ω–∏–∏')
        if company_id and company_id not in self.processed_ids:
            self.all_data.append(data)
            self.processed_ids.add(company_id)
            
            # –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            if len(self.all_data) % CONFIG.batch_size == 0:
                self.save_to_excel()
                logger.info(f"–ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: {len(self.all_data)} –∑–∞–ø–∏—Å–µ–π")
    
    def save_to_excel(self) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ Excel"""
        if not self.all_data:
            return False
        
        try:
            df = pd.DataFrame(self.all_data)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤
            priority_columns = [
                'id_–∫–æ–º–ø–∞–Ω–∏–∏', '—Å—Ç–∞—Ç—É—Å', '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', '—Å–æ–∫—Ä–∞—â–µ–Ω–Ω–æ–µ_–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ',
                '–∏–Ω–Ω', '–∫–ø–ø', '–æ–≥—Ä–Ω', '—Ç–∏–ø_–∑–∞—è–≤–∏—Ç–µ–ª—è', '–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ_–ø—Ä–∞–≤–æ–≤–∞—è_—Ñ–æ—Ä–º–∞',
                '—É–Ω–∏–∫–∞–ª—å–Ω—ã–π_–Ω–æ–º–µ—Ä_–∑–∞–ø–∏—Å–∏', '—Å—Ç–∞—Ç—É—Å_–∞–∫–∫—Ä–µ–¥–∏—Ç–∞—Ü–∏–∏', '–¥–∞—Ç–∞_–∞–∫–∫—Ä–µ–¥–∏—Ç–∞—Ü–∏–∏',
                '—Ç–µ–ª–µ—Ñ–æ–Ω', 'email', '—Å–∞–π—Ç', '–∞–¥—Ä–µ—Å_–º–µ—Å—Ç–∞_–Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è',
                '—Ñ–∏–æ_—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è', '–¥–æ–ª–∂–Ω–æ—Å—Ç—å_—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è',
                '–¥–∞—Ç–∞_–≤–Ω–µ—Å–µ–Ω–∏—è_–≤_—Ä–µ–µ—Å—Ç—Ä', '–≤–∫–ª—é—á–µ–Ω_–≤_–Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é_—á–∞—Å—Ç—å',
                '—Å—Ç–∞—Ç—É—Å_–æ–±—Ä–∞–±–æ—Ç–∫–∏', '–æ—à–∏–±–∫–∏_–¥–µ–∫–ª–∞—Ä–∞—Ü–∏–∏', '–¥–∞—Ç–∞_–ø–∞—Ä—Å–∏–Ω–≥–∞'
            ]
            
            # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã
            existing_columns = list(df.columns)
            ordered_columns = []
            
            for col in priority_columns:
                if col in existing_columns:
                    ordered_columns.append(col)
                    if col in existing_columns:
                        existing_columns.remove(col)
            
            ordered_columns.extend(sorted(existing_columns))
            df = df[ordered_columns]
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Excel
            df.to_excel(self.output_file, index=False, engine='openpyxl')
            
            # –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è –≤ CSV
            csv_file = self.output_file.with_suffix('.csv')
            df.to_csv(csv_file, index=False, encoding='utf-8-sig')
            
            logger.info(f"‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –≤ {self.output_file}")
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è Excel: {e}")
            
            # –≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON
            try:
                json_file = self.output_file.with_suffix('.json')
                with open(json_file, 'w', encoding='utf-8') as f:
                    json.dump(self.all_data, f, ensure_ascii=False, indent=2)
                logger.info(f"–≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON: {json_file}")
            except:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–∂–µ –≤ JSON")
            
            return False
    
    def get_stats(self) -> Dict[str, int]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        if not self.all_data:
            return {"total": 0, "unique": 0}
        
        status_stats = {}
        error_stats = {}
        
        for item in self.all_data:
            status = item.get('—Å—Ç–∞—Ç—É—Å_–æ–±—Ä–∞–±–æ—Ç–∫–∏', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
            error = item.get('–æ—à–∏–±–∫–∏_–¥–µ–∫–ª–∞—Ä–∞—Ü–∏–∏', '–ù–µ—Ç')
            
            status_stats[status] = status_stats.get(status, 0) + 1
            if error != '–ù–µ—Ç':
                error_stats[error] = error_stats.get(error, 0) + 1
        
        return {
            "total": len(self.all_data),
            "unique": len(self.processed_ids),
            "status_stats": status_stats,
            "error_stats": error_stats
        }

# ================= –û–°–ù–û–í–ù–û–ô –ü–ê–†–°–ï–† =================
class FSAParser:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –ø–∞—Ä—Å–µ—Ä–∞"""
    
    def __init__(self):
        self.data_manager = DataManager()
        self.api_client = APIClient()
        self.data_processor = DataProcessor()
        
        self.total_processed = 0
        self.total_success = 0
        self.total_server_errors = 0
        self.total_failed = 0
        
    def load_company_ids(self) -> List[str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ ID –∫–æ–º–ø–∞–Ω–∏–π –∏–∑ —Ñ–∞–π–ª–æ–≤"""
        possible_files = [
            "company_ids.txt",
            "links.txt",
            "ids.txt",
            "input.txt",
            "—Å–ø–∏—Å–æ–∫.txt"
        ]
        
        all_ids = []
        
        for filename in possible_files:
            filepath = Path(filename)
            if filepath.exists():
                try:
                    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ ID –∏–∑ {filename}")
                    
                    content = filepath.read_text(encoding='utf-8', errors='ignore')
                    lines = [line.strip() for line in content.split('\n') if line.strip()]
                    
                    for line in lines:
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
                        if line.startswith('#') or line.startswith('//'):
                            continue
                        
                        company_id = extract_company_id(line)
                        if company_id and company_id.isdigit():
                            all_ids.append(company_id)
                        elif line.isdigit():
                            all_ids.append(line)
                    
                    logger.info(f"  –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(lines)} —Å—Ç—Ä–æ–∫ –∏–∑ {filename}")
                    
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {filename}: {e}")
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        seen = set()
        unique_ids = []
        for id_ in all_ids:
            if id_ not in seen:
                seen.add(id_)
                unique_ids.append(id_)
        
        logger.info(f"–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ID: {len(unique_ids)}")
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤ - —Å–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ
        if not unique_ids:
            logger.warning("–§–∞–π–ª—ã —Å ID –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –°–æ–∑–¥–∞—é —Ç–µ—Å—Ç–æ–≤—ã–µ ID 1-100")
            unique_ids = [str(i) for i in range(1, 101)]
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if CONFIG.max_records > 0 and len(unique_ids) > CONFIG.max_records:
            logger.info(f"–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–æ {CONFIG.max_records} –∑–∞–ø–∏—Å–µ–π")
            unique_ids = unique_ids[:CONFIG.max_records]
        
        return unique_ids
    
    async def process_single_company(self, session: aiohttp.ClientSession, 
                                    company_id: str, idx: int, total: int) -> Optional[Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –∫–æ–º–ø–∞–Ω–∏–∏"""
        try:
            logger.debug(f"[{idx}/{total}] –ó–∞–ø—Ä–æ—Å –∫–æ–º–ø–∞–Ω–∏–∏ {company_id}")
            
            # 1. –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏
            company_data = await self.api_client.get_company(session, company_id)
            
            if not company_data or company_data.get('_status') in ['NOT_FOUND', 'SERVER_ERROR']:
                self.total_failed += 1
                logger.warning(f"[{idx}] –ö–æ–º–ø–∞–Ω–∏—è {company_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞")
                return {
                    'id_–∫–æ–º–ø–∞–Ω–∏–∏': company_id,
                    '—Å—Ç–∞—Ç—É—Å': '–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–ª–∏ –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞',
                    '—Å—Ç–∞—Ç—É—Å_–æ–±—Ä–∞–±–æ—Ç–∫–∏': '–û–®–ò–ë–ö–ê_API',
                    '–¥–∞—Ç–∞_–ø–∞—Ä—Å–∏–Ω–≥–∞': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
            
            # 2. –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –¥–µ–∫–ª–∞—Ä–∞—Ü–∏—é
            decl_data = {"_status": "NO_DOC_ID"}
            accreditation = safe_get(company_data, 'accreditation', default={})
            
            if isinstance(accreditation, dict):
                doc_id = safe_get(accreditation, 'idAccredScopeFile')
                if doc_id:
                    try:
                        decl_data = await self.api_client.get_declaration(session, doc_id)
                    except Exception as e:
                        logger.warning(f"[{idx}] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –¥–µ–∫–ª–∞—Ä–∞—Ü–∏–∏: {e}")
                        decl_data = {"_status": "REQUEST_ERROR", "error": str(e)}
            
            # 3. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            result = self.data_processor.process_company(company_id, company_data, decl_data)
            
            # 4. –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.total_processed += 1
            
            if result.get('—Å—Ç–∞—Ç—É—Å_–æ–±—Ä–∞–±–æ—Ç–∫–∏') == '–£–°–ü–ï–®–ù–û':
                self.total_success += 1
            elif result.get('–æ—à–∏–±–∫–∏_–¥–µ–∫–ª–∞—Ä–∞—Ü–∏–∏', '–ù–µ—Ç') != '–ù–µ—Ç':
                self.total_server_errors += 1
            else:
                self.total_failed += 1
            
            # 5. –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            status_icon = "‚úÖ" if result.get('—Å—Ç–∞—Ç—É—Å_–æ–±—Ä–∞–±–æ—Ç–∫–∏') == '–£–°–ü–ï–®–ù–û' else "‚ö†Ô∏è"
            logger.info(f"[{idx}] {status_icon} {result.get('–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', company_id)[:50]}...")
            
            return result
            
        except Exception as e:
            self.total_failed += 1
            logger.error(f"[{idx}] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {company_id}: {e}")
            logger.error(traceback.format_exc())
            
            return {
                'id_–∫–æ–º–ø–∞–Ω–∏–∏': company_id,
                '—Å—Ç–∞—Ç—É—Å': f'–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)[:100]}',
                '—Å—Ç–∞—Ç—É—Å_–æ–±—Ä–∞–±–æ—Ç–∫–∏': '–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø_–û–®–ò–ë–ö–ê',
                '–¥–∞—Ç–∞_–ø–∞—Ä—Å–∏–Ω–≥–∞': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
    
    async def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞"""
        logger.info("=" * 70)
        logger.info("üöÄ –ó–ê–ü–£–°–ö –ü–ê–†–°–ï–†–ê –†–ï–ï–°–¢–†–ê –§–°–ê")
        logger.info(f"üìÅ –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {CONFIG.output_file}")
        logger.info(f"üßµ –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å: {CONFIG.concurrency}")
        logger.info("=" * 70)
        
        start_time = time.time()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ ID
        company_ids = self.load_company_ids()
        total = len(company_ids)
        
        if total == 0:
            logger.error("‚ùå –ù–µ—Ç ID –∫–æ–º–ø–∞–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!")
            return
        
        logger.info(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total}")
        
        # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é
        connector = aiohttp.TCPConnector(
            limit=CONFIG.concurrency,
            limit_per_host=CONFIG.concurrency,
            ssl=False
        )
        
        async with aiohttp.ClientSession(
            headers=self.api_client.headers,
            connector=connector,
            timeout=self.api_client.timeout
        ) as session:
            
            # –°–æ–∑–¥–∞–µ–º —Å–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
            semaphore = asyncio.Semaphore(CONFIG.concurrency)
            
            async def process_with_limit(company_id: str, idx: int):
                async with semaphore:
                    return await self.process_single_company(session, company_id, idx, total)
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏
            tasks = []
            for idx, company_id in enumerate(company_ids, 1):
                tasks.append(process_with_limit(company_id, idx))
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–¥–∞—á–∏
            completed = 0
            last_log_time = time.time()
            
            for idx, task in enumerate(asyncio.as_completed(tasks), 1):
                try:
                    result = await task
                    completed += 1
                    
                    if result:
                        self.data_manager.add_data(result)
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 –∑–∞–ø–∏—Å–µ–π –∏–ª–∏ 30 —Å–µ–∫—É–Ω–¥
                    current_time = time.time()
                    if (completed % 10 == 0) or (current_time - last_log_time > 30):
                        elapsed = current_time - start_time
                        speed = completed / elapsed if elapsed > 0 else 0
                        remaining = total - completed
                        eta = remaining / speed if speed > 0 else 0
                        
                        logger.info(
                            f"üìà –ü—Ä–æ–≥—Ä–µ—Å—Å: {completed}/{total} ({completed/total*100:.1f}%) | "
                            f"–°–∫–æ—Ä–æ—Å—Ç—å: {speed:.1f}/—Å–µ–∫ | "
                            f"–£—Å–ø–µ—à–Ω–æ: {self.total_success} | "
                            f"–û—à–∏–±–∫–∏ 500: {self.total_server_errors} | "
                            f"–°–±–æ–µ–≤: {self.total_failed} | "
                            f"–û—Å—Ç–∞–ª–æ—Å—å: ~{eta/60:.0f} –º–∏–Ω"
                        )
                        
                        last_log_time = current_time
                    
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –∑–∞–¥–∞—á–µ {idx}: {e}")
                    self.total_failed += 1
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        self.data_manager.save_to_excel()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        end_time = time.time()
        total_time = end_time - start_time
        stats = self.data_manager.get_stats()
        
        logger.info("=" * 70)
        logger.info("‚úÖ –ü–ê–†–°–ò–ù–ì –ó–ê–í–ï–†–®–ï–ù!")
        logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {self.total_processed}")
        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {self.total_success}")
        logger.info(f"‚ö†Ô∏è  –û—à–∏–±–∫–∏ –¥–µ–∫–ª–∞—Ä–∞—Ü–∏–π: {self.total_server_errors}")
        logger.info(f"‚ùå –°–±–æ–µ–≤: {self.total_failed}")
        logger.info(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time/60:.1f} –º–∏–Ω—É—Ç")
        logger.info(f"üöÄ –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {self.total_processed/total_time:.1f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫")
        logger.info(f"üíæ –§–∞–π–ª: {CONFIG.output_file}")
        logger.info("=" * 70)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º
        if 'status_stats' in stats:
            logger.info("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –°–¢–ê–¢–£–°–ê–ú:")
            for status, count in stats['status_stats'].items():
                logger.info(f"  {status}: {count}")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        self.create_report(total_time, stats)
    
    def create_report(self, total_time: float, stats: Dict):
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –ø–∞—Ä—Å–∏–Ω–≥–µ"""
        report = f"""
–û–¢–ß–ï–¢ –û –ü–ê–†–°–ò–ù–ì–ï –†–ï–ï–°–¢–†–ê –§–°–ê
{'=' * 50}

–î–ê–¢–ê –í–´–ü–û–õ–ù–ï–ù–ò–Ø: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

–°–¢–ê–¢–ò–°–¢–ò–ö–ê:
- –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {self.total_processed + self.total_failed}
- –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.total_success}
- –ó–∞–ø–∏—Å–µ–π —Å –æ—à–∏–±–∫–∞–º–∏ –¥–µ–∫–ª–∞—Ä–∞—Ü–∏–π: {self.total_server_errors}
- –ó–∞–ø–∏—Å–µ–π —Å–æ —Å–±–æ—è–º–∏: {self.total_failed}
- –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {(self.total_success/self.total_processed*100):.1f}%

–í–†–ï–ú–Ø –í–´–ü–û–õ–ù–ï–ù–ò–Ø:
- –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time/60:.1f} –º–∏–Ω—É—Ç
- –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {self.total_processed/total_time:.1f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫

–í–´–•–û–î–ù–´–ï –§–ê–ô–õ–´:
1. {CONFIG.output_file} - –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª Excel
2. {CONFIG.output_file.replace('.xlsx', '.csv')} - —Ä–µ–∑–µ—Ä–≤–Ω—ã–π —Ñ–∞–π–ª CSV
3. {CONFIG.log_file} - —Ñ–∞–π–ª –ª–æ–≥–æ–≤

–°–¢–ê–¢–£–°–´ –û–ë–†–ê–ë–û–¢–ö–ò:
"""
        
        if 'status_stats' in stats:
            for status, count in stats['status_stats'].items():
                report += f"- {status}: {count}\n"
        
        report += f"""
–ü–†–ò–ú–ï–ß–ê–ù–ò–Ø:
1. –û—à–∏–±–∫–∏ HTTP 500 - —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º—ã –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ —Å–µ—Ä–≤–µ—Ä–∞ –§–°–ê
2. –î–∞–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö –¥–µ–∫–ª–∞—Ä–∞—Ü–∏–π
3. –î–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ —É–¥–∞–ª–∏—Ç–µ —Ñ–∞–π–ª {CONFIG.output_file}
4. –õ–æ–≥ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–∞—Ö
"""
        
        report_file = "–æ—Ç—á–µ—Ç_–æ_–ø–∞—Ä—Å–∏–Ω–≥–µ.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {report_file}")

# ================= –ö–û–ú–ê–ù–î–´ –ò –ó–ê–ü–£–°–ö =================
def print_banner():
    """–í—ã–≤–æ–¥ –±–∞–Ω–Ω–µ—Ä–∞"""
    banner = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë           –ü–ê–†–°–ï–† –†–ï–ï–°–¢–†–ê –§–°–ê v3.0               ‚ïë
‚ïë     –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å pub.fsa.gov.ru/ral            ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""
    print(banner)

def check_environment():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Python
    print(f"  Python: {sys.version.split()[0]}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫
    required = ['aiohttp', 'pandas', 'openpyxl']
    for lib in required:
        try:
            __import__(lib)
            print(f"  ‚úÖ {lib}")
        except ImportError:
            print(f"  ‚ùå {lib} - —Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤
    input_files = ["company_ids.txt", "links.txt", "ids.txt"]
    found = False
    for file in input_files:
        if Path(file).exists():
            print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {file}")
            found = True
    
    if not found:
        print("  ‚ö†Ô∏è  –§–∞–π–ª—ã —Å ID –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ë—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª.")

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print_banner()
    
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
    else:
        command = "help"
    
    if command == "run":
        print("üöÄ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞...")
        check_environment()
        parser = FSAParser()
        await parser.run()
        
    elif command == "test":
        print("üß™ –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ (100 –∑–∞–ø–∏—Å–µ–π)...")
        CONFIG.max_records = 100
        CONFIG.output_file = "—Ç–µ—Å—Ç_—Ä–µ–µ—Å—Ç—Ä.xlsx"
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        if not Path("company_ids.txt").exists():
            with open("company_ids.txt", "w", encoding="utf-8") as f:
                for i in range(1, 101):
                    f.write(f"{i}\n")
            print("‚úì –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª company_ids.txt —Å–æ 100 ID")
        
        parser = FSAParser()
        await parser.run()
        
    elif command == "check":
        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ API –∏ —Ç–æ–∫–µ–Ω–∞...")
        import requests
        
        test_url = f"{CONFIG.base_url}/api/v1/ral/common/companies/1"
        headers = CONFIG.headers.copy()
        
        try:
            response = requests.get(test_url, headers=headers, timeout=10)
            print(f"–°—Ç–∞—Ç—É—Å API: {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                print("‚úÖ API –¥–æ—Å—Ç—É–ø–µ–Ω –∏ —Ç–æ–∫–µ–Ω –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω")
                print(f"–ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:")
                print(f"  ID: {data.get('id')}")
                print(f"  –ù–∞–∑–≤–∞–Ω–∏–µ: {data.get('fullName')}")
                print(f"  –ò–ù–ù: {data.get('inn')}")
                print(f"  –°—Ç–∞—Ç—É—Å: {data.get('status')}")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏–º–µ—Ä
                with open("–ø—Ä–∏–º–µ—Ä_–æ—Ç–≤–µ—Ç–∞_api.json", "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                print("‚úì –ü—Ä–∏–º–µ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ '–ø—Ä–∏–º–µ—Ä_–æ—Ç–≤–µ—Ç–∞_api.json'")
                
            elif response.status_code == 401:
                print("‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏. –¢–æ–∫–µ–Ω –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω.")
                print("–û–±–Ω–æ–≤–∏—Ç–µ —Ç–æ–∫–µ–Ω –≤ —Ñ–∞–π–ª–µ CONFIG.auth_token")
            elif response.status_code == 500:
                print("‚ö†Ô∏è  –°–µ—Ä–≤–µ—Ä –≤–µ—Ä–Ω—É–ª 500 –æ—à–∏–±–∫—É. –ü—Ä–æ–±–ª–µ–º—ã –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ –§–°–ê.")
            else:
                print(f"‚ö†Ô∏è  –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å: {response.status_code}")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
        
    elif command == "generate":
        print("üìù –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å 38000 ID...")
        try:
            with open("company_ids_full.txt", "w", encoding="utf-8") as f:
                for i in range(1, 38001):
                    f.write(f"{i}\n")
                    if i % 5000 == 0:
                        print(f"  –ó–∞–ø–∏—Å–∞–Ω–æ {i} ID...")
            print(f"‚úì –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª 'company_ids_full.txt' —Å 38000 ID")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
    
    elif command == "help":
        print("""
üìñ –°–ü–†–ê–í–ö–ê –ü–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ:

–ö–æ–º–∞–Ω–¥—ã:
  python fsa_parser.py run      - –ü–æ–ª–Ω—ã–π –∑–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞
  python fsa_parser.py test     - –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ (100 –∑–∞–ø–∏—Å–µ–π)
  python fsa_parser.py check    - –ü—Ä–æ–≤–µ—Ä–∫–∞ API –∏ —Ç–æ–∫–µ–Ω–∞
  python fsa_parser.py generate - –°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª —Å 38000 ID
  python fsa_parser.py help     - –≠—Ç–∞ —Å–ø—Ä–∞–≤–∫–∞

–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞:
  1. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª company_ids.txt —Å ID –∫–æ–º–ø–∞–Ω–∏–π
     (–∫–∞–∂–¥—ã–π ID –Ω–∞ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–µ: 1, 2, 3, ... 38000)
  
  2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ: python fsa_parser.py check
  
  3. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ: python fsa_parser.py test
  
  4. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥: python fsa_parser.py run

–§–∞–π–ª—ã:
  - company_ids.txt - —Å–ø–∏—Å–æ–∫ ID –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
  - —Ä–µ–µ—Å—Ç—Ä_—Ñ—Å–∞.xlsx - —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–∞—Ä—Å–∏–Ω–≥–∞
  - fsa_parser.log - –ø–æ–¥—Ä–æ–±–Ω—ã–π –ª–æ–≥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
  - –æ—Ç—á–µ—Ç_–æ_–ø–∞—Ä—Å–∏–Ω–≥–µ.txt - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

–ü—Ä–∏–º–µ—á–∞–Ω–∏—è:
  - –ü—Ä–∏ –æ—à–∏–±–∫–∞—Ö HTTP 500 –¥–∞–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è
  - –î–µ–∫–ª–∞—Ä–∞—Ü–∏–∏ –º–æ–≥—É—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π
  - –¢–æ–∫–µ–Ω –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
""")
    
    else:
        print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞: {command}")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: python fsa_parser.py help")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  –ü–∞—Ä—Å–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        print("üìÅ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ç–µ–∫—É—â–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏")
    except Exception as e:
        print(f"\n\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        print("–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –≤ –ª–æ–≥-—Ñ–∞–π–ª–µ")
        traceback.print_exc()
